{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "from hyperopt import fmin\n",
    "from hyperopt import tpe\n",
    "import math\n",
    "import numpy as np\n",
    "import argparse\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__FILE_' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-b0a5a274b93b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mscript_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__FILE_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodule_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscript_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'..'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'..'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mdistiller\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name '__FILE_' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "script_dir = os.path.dirname(__FILE_)\n",
    "module_path = os.path.abspath(os.path.join(script_dir, '..', '..'))\n",
    "try:\n",
    "    import distiller\n",
    "except ImportError:\n",
    "    sys.path.append(module_path)\n",
    "    import distiller\n",
    "import apputils\n",
    "from models import ALL_MODEL_NAMES, create_model\n",
    "\n",
    "def float_range(val_str):\n",
    "    val = float(val_str)\n",
    "    if val < 0 or val >= 1:\n",
    "        raise argparse.ArgumentTypeError('Must be >= 0 and < 1 (received {0})'.format(val_str))\n",
    "    return val\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Distiller image classification model compression')\n",
    "parser.add_argument('data', metavar='DIR', help='path to dataset')\n",
    "parser.add_argument('--arch', '-a', metavar='ARCH', default='resnet20_cifar',\n",
    "                    choices=ALL_MODEL_NAMES,\n",
    "                    help='model architecture: ' +\n",
    "                    ' | '.join(ALL_MODEL_NAMES) +\n",
    "                    ' (default: resnet20_cifar)')\n",
    "parser.add_argument('-r', '--rounds', default=10, type=int,\n",
    "                    metavar='R', help='max rounds (default: 10)')\n",
    "parser.add_argument('--epochs', default=120, type=int,\n",
    "                    metavar='E', help='epochs (default: 120)')\n",
    "parser.add_argument('-j', '--workers', default=1, type=int, metavar='N',\n",
    "                    help='number of data loading workers (default: 1)')\n",
    "parser.add_argument('-b', '--batch-size', default=128, type=int,\n",
    "                    metavar='N', help='mini-batch size (default: 128)')\n",
    "parser.add_argument('--gpus', metavar='DEV_ID', default=None,\n",
    "                    help='Comma-separated list of GPU device IDs to be used (default is to use all available devices)')\n",
    "parser.add_argument('--lr', '--learning-rate', default=0.01, type=float,\n",
    "                    metavar='LR', help='initial learning rate')\n",
    "parser.add_argument('--momentum', default=0.9, type=float, metavar='M',\n",
    "                    help='momentum')\n",
    "parser.add_argument('--weight-decay', '--wd', default=1e-4, type=float,\n",
    "                    metavar='W', help='weight decay (default: 1e-4)')\n",
    "parser.add_argument('--validation-size', '--vs', type=float_range, default=0.1,\n",
    "                    help='Portion of training dataset to set aside for validation')\n",
    "parser.add_argument('--deterministic', '--det', action='store_true',\n",
    "                    help='Ensure deterministic execution for re-producible results.')\n",
    "# Manual setting hyperparameters \n",
    "args = parser.parse_args()\n",
    "args.dataset = 'cifar10' if 'cifar' in args.arch else 'imagenet'\n",
    "if args.gpus is not None:\n",
    "\ttry:\n",
    "\t\targs.gpus = [int(s) for s in args.gpus.split(',')]\n",
    "\texcept ValueError:\n",
    "\t\texit(1)\n",
    "\tavailable_gpus = torch.cuda.device_count()\n",
    "\tfor dev_id in args.gpus:\n",
    "\t\tif dev_id >= available_gpus:\n",
    "\t\t\texit(1)\n",
    "\t# Set default device in case the first one on the list != 0\n",
    "\ttorch.cuda.set_device(args.gpus[0])\n",
    "model = create_model(False, args.dataset, args.arch, device_ids=args.gpus) # Get arch state_dict\n",
    "train_loader, val_loader, test_loader, _ = apputils.load_data(\n",
    "        args.dataset, os.path.expanduser(args.data), args.batch_size,\n",
    "        args.workers, args.validation_size, args.deterministic)\n",
    "\n",
    "count = 0\n",
    "def objective(space):\n",
    "    global model\n",
    "    global count\n",
    "    #Explore new model\n",
    "    model = create_model(False, args.dataset, args.arch, device_ids=args.gpus)\n",
    "    count += 1\n",
    "    # Objective function: F(Acc, Lat) = (1 - Acc.) + (alpha * Sparsity)\n",
    "    accuracy = 0\n",
    "    alpha = 0.2 # Super-parameter: the importance of inference time\n",
    "    latency = 0.0\n",
    "    sparsity = 0.0\n",
    "    # Training hyperparameter\n",
    "    criterion = nn.CrossEntropyLoss().cuda()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=args.lr,\n",
    "                                momentum=args.momentum,\n",
    "                                weight_decay=args.weight_decay)\n",
    "    \"\"\"\n",
    "    distiller/distiller/config.py\n",
    "        # Element-wise sparsity\n",
    "        sparsity_levels = {net_param: sparsity_level}\n",
    "        pruner = distiller.pruning.SparsityLevelParameterPruner(name='sensitivity', levels=sparsity_levels)\n",
    "        policy = distiller.PruningPolicy(pruner, pruner_args=None)\n",
    "        scheduler = distiller.CompressionScheduler(model)\n",
    "        scheduler.add_policy(policy, epochs=[0, 2, 4])\n",
    "        # Local search \n",
    "        add multiple pruner for each layer\n",
    "    \"\"\"\n",
    "    sparsity_levels = {}\n",
    "    for key, value in space.items():\n",
    "        sparsity_levels[key] = value\n",
    "    pruner = distiller.pruning.SparsityLevelParameterPruner(name='sensitivity', levels=sparsity_levels)\n",
    "    policy = distiller.PruningPolicy(pruner, pruner_args=None)\n",
    "    lrpolicy = distiller.LRPolicy(torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1))\n",
    "    compression_scheduler = distiller.CompressionScheduler(model)\n",
    "    compression_scheduler.add_policy(policy, epochs=[90])\n",
    "    compression_scheduler.add_policy(lrpolicy, starting_epoch=0, ending_epoch=90, frequency=1)\n",
    "    \"\"\"\n",
    "    distiller/example/classifier_compression/compress_classifier.py\n",
    "    For each epoch:\n",
    "        compression_scheduler.on_epoch_begin(epoch)\n",
    "        train()\n",
    "        save_checkpoint()\n",
    "        compression_scheduler.on_epoch_end(epoch)\n",
    "\n",
    "    train():\n",
    "        For each training step:\n",
    "            compression_scheduler.on_minibatch_begin(epoch)\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target)\n",
    "            compression_scheduler.before_backward_pass(epoch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            compression_scheduler.on_minibatch_end(epoch)\n",
    "    \"\"\"\n",
    "    for i in range(args.epochs):\n",
    "        compression_scheduler.on_epoch_begin(i)\n",
    "        train_accuracy = train(i,criterion, optimizer, compression_scheduler)\n",
    "        val_accuracy = validate() # Validate hyperparameter setting\n",
    "        t, sparsity = distiller.weights_sparsity_tbl_summary(model, return_total_sparsity=True)\n",
    "        compression_scheduler.on_epoch_end(i, optimizer)\n",
    "        apputils.save_checkpoint(i, args.arch, model, optimizer, compression_scheduler, train_accuracy, False,\n",
    "                                         'hyperopt', './')\n",
    "    test_accuracy = test() # Validate hyperparameter setting\n",
    "    score = (1-(val_accuracy/100.)) + (alpha * (1-sparsity/100.)) # objective funtion here\n",
    "    print('{} trials: score: {:.4f}\\ttrain acc:{:.4f}\\tval acc:{:.4f}\\ttest acc:{:.4f}\\tsparsity:{:.4f}'.format(count, \n",
    "                                      score, \n",
    "                                      train_accuracy, \n",
    "                                      val_accuracy, \n",
    "                                      test_accuracy,\n",
    "                                      sparsity))\n",
    "    return score\n",
    "\n",
    "def train(epoch, criterion, optimizer, compression_scheduler):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    total_samples = len(train_loader.sampler)\n",
    "    batch_size = train_loader.batch_size\n",
    "    steps_per_epoch = math.ceil(total_samples / batch_size)\n",
    "    for train_step, (inputs, targets) in enumerate(train_loader):\n",
    "        compression_scheduler.on_minibatch_begin(epoch, train_step, steps_per_epoch, optimizer)\n",
    "        inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        outputs = model(inputs.cuda())\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets.data).cpu().sum().data.numpy()\n",
    "        loss = criterion(outputs, targets)\n",
    "        compression_scheduler.before_backward_pass(epoch, train_step, steps_per_epoch, loss,\n",
    "                                                   optimizer=optimizer, return_loss_components=True)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        compression_scheduler.on_minibatch_end(epoch, train_step, steps_per_epoch, optimizer)\n",
    "    accuracy = 100. * correct / total    \n",
    "    return accuracy\n",
    "def validate():\n",
    "    model.eval() \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for test_step, (inputs, targets) in enumerate(val_loader):\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets.data).cpu().sum().data.numpy()\n",
    "    accuracy = 100. * correct / total    \n",
    "    return accuracy\n",
    "    \n",
    "def test():\n",
    "    model.eval() \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for test_step, (inputs, targets) in enumerate(test_loader):\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets.data).cpu().sum().data.numpy()\n",
    "    accuracy = 100. * correct / total    \n",
    "    return accuracy\n",
    "def get_space():\n",
    "    space = {}\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if 'conv' in name and 'weight' in name:\n",
    "            space[name] = hp.uniform(name, 0.01, 0.99)\n",
    "    return space\n",
    "\n",
    "def main():\n",
    "    space = get_space()\n",
    "    best = fmin(objective, space, algo=tpe.suggest, max_evals=args.rounds)\n",
    "    print(best)\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
